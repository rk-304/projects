{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'dwl-postgres.cvwuspqh0afz.us-east-1.rds.amazonaws.com'\n",
    "port = '5432'\n",
    "user = 'postgres'\n",
    "password = 'postgres'\n",
    "db_name = 'DWL09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host, user=user,port=port,\n",
    "                           passwd=password, db=dbname)\n",
    "\n",
    "tw_list = pd.read_sql('SELECT user.screen_name, text FROM tweet13;', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_list.columns = [\"user_account\",\"text\"]\n",
    "tw_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_list['text'] = tw_list['text'].str.lower()\\\n",
    ".str.replace('(@[a-z0-9]+)\\w+',' ')\\\n",
    ".str.replace('(http\\S+)', ' ')\\\n",
    ".str.replace('([^0-9a-z \\t])',' ')\\\n",
    ".str.replace(' +',' ')\\\n",
    ".str.replace('(&gt)', '')\\\n",
    ".str.replace('(\\xa0)', '')\\\n",
    ".str.replace('(&amp)', '')\\\n",
    ".str.replace('(&lt)', '')\\\n",
    ".str.replace('(<a).*(>).*(</a>)', '')\\\n",
    ".str.replace(\"(<br/>)\", \"\")\\\n",
    ".str.replace(\"(rt)\", \"\")\n",
    "\n",
    "tw_list.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_list.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Negative, Positive, Neutral and Compound values\n",
    "tw_list[['polarity', 'subjectivity']] = tw_list['text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    "for index, row in tw_list['text'].iteritems():\n",
    "        score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "        neg = score['neg']\n",
    "        neu = score['neu']\n",
    "        pos = score['pos']\n",
    "        comp = score['compound']\n",
    "\n",
    "tw_list['neg'] = tw_list['text'].apply(lambda x:SentimentIntensityAnalyzer().polarity_scores(x)['neg'])\n",
    "tw_list['neu'] = tw_list['text'].apply(lambda x:SentimentIntensityAnalyzer().polarity_scores(x)['neu'])\n",
    "tw_list['pos'] = tw_list['text'].apply(lambda x:SentimentIntensityAnalyzer().polarity_scores(x)['pos'])\n",
    "tw_list['compound'] = tw_list['text'].apply(lambda x:SentimentIntensityAnalyzer().polarity_scores(x)['compound'])\n",
    "\n",
    "tw_list.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "additional  = ['rt','rts','retweet'] #we'll store additional stopwords here\n",
    "swords = set().union(stopwords.words('english'),additional)\n",
    "\n",
    "tw_list.drop_duplicates(subset='text',inplace=True)\n",
    "\n",
    "tw_list['text'] = tw_list['text'].str.lower()\\\n",
    ".str.replace('(@[a-z0-9]+)\\w+',' ')\\\n",
    ".str.replace('(http\\S+)', ' ')\\\n",
    ".str.replace('([^0-9a-z \\t])',' ')\\\n",
    ".str.replace(' +',' ')\\\n",
    ".str.replace('(&gt)', '')\\\n",
    ".str.replace('(\\xa0)', '')\\\n",
    ".str.replace('(&amp)', '')\\\n",
    ".str.replace('(&lt)', '')\\\n",
    ".str.replace('(<a).*(>).*(</a>)', '')\\\n",
    ".str.replace(\"(<br/>)\", \"\")\\\n",
    ".apply(lambda x: [i for i in x.split() if not i in swords])\n",
    "#  ReviewText = ReviewText.str.replace(\"(<br/>)\", \"\")\n",
    "#     ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')\n",
    "#     ReviewText = ReviewText.str.replace('(&amp)', '')\n",
    "#     ReviewText = ReviewText.str.replace('(&gt)', '')\n",
    "#     ReviewText = ReviewText.str.replace('(&lt)', '')\n",
    "#     ReviewText = ReviewText.str.replace('(\\xa0)', ' ')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_list.head(n=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "tw_list['stemmed'] = tw_list['text'].apply(lambda x: [ps.stem(i) for i in x if i != ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.sentiment.vader as vd\n",
    "from nltk import download\n",
    "#download('vader_lexicon')\n",
    "\n",
    "sia = vd.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "tw_list['sentiment_score'] = tw_list['text'].apply(lambda x: sum([ sia.polarity_scores(i)['compound'] for i in word_tokenize( ' '.join(x) )]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_list[['text','sentiment_score']].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_list['sentiment_score'].apply(lambda x: round(x,)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_list[tw_list['sentiment_score'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_list[\"sentiment_score'\"] = None\n",
    "tw_list.to_sql(\"tweet13\", conn, if_exists=\"replace\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
